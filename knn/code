1.KNN（K-Nearest Neighbor）工作原理：

  存在一个样本数据集合，也称为训练样本集，并且样本集中每个数据都存在标签，即我们知道
样本集中每一数据与所属分类对应的关系。输入没有标签的数据后，将新数据中的每个特征与
样本集中数据对应的特征进行比较，提取出样本集中特征最相似数据（最近邻）的分类标签。
一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k近邻算法中k的出处，
通常k是不大于20的整数。最后选择k个最相似数据中出现次数最多的分类作为新数据的分类。

2.knn算法的优缺点：

   优点：精度高，对异常值不敏感、无数据输入假定

　　缺点：计算复杂度高、空间复杂度高

3.python实现：

    1).计算距离
    2).选择距离最小的k个点
    3).排序

    1).引入各种库
    2).对数据进行处理（全部变成float，去掉缺失值，归一化，标准化）
    3).计算距离
    4).排序
    5).选择距离最小的k个点
    6).计算出预测值
    7).计算出RMSE（误差）    

4.例： 房价

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

#对数据进行处理：
features = ['accommodates','bedrooms','bathrooms','beds','price','minimum_nights','maximum_nights','number_of_reviews']

dc_listings = pd.read_csv('listings.csv')

dc_listings = dc_listings[features]
print(dc_listings.shape)

dc_listings.head()

our_acc_value = 3

dc_listings['distance'] = np.abs(dc_listings.accommodates - our_acc_value)
dc_listings.distance.value_counts().sort_index()
#此时的DF还没有按照distance来排序

dc_listings = dc_listings.sample(frac=1,random_state=0)
#洗牌!!!!!!!!!!!!!!!!!!!!!!

dc_listings = dc_listings.sort_values('distance')
print(dc_listings.head())
dc_listings.price.head()

dc_listings['price'] = dc_listings.price.str.replace("\$|,",'').astype(float)
#将价格的 $符号去掉

mean_price = dc_listings.price.iloc[:5].mean()
mean_price
#前五个距离为0的房子的平均房价

#！！！！！！！！！！！！！！！！！！！！
#对模型评估（RMSE均方根误差）

dc_listings.drop('distance',axis=1)
#distance不要了，将其删除
train_df = dc_listings.copy().iloc[:2792]
test_df = dc_listings.copy().iloc[2792:]
                      #copy为强复制，不同地址不同值
#！！！！！！！！！！！！！！！！！！！！！！！！
#iloc按照行号来索引，而loc按照index来索引

A         B
0  1.068932 -0.794307
2 -0.470056  1.192211
4 -0.284561  0.756029
6  1.037563 -0.267820
8 -0.538478 -0.800654

In [5]: df.iloc[[2]]
Out[5]:
        A         B
4 -0.284561  0.756029

In [6]: df.loc[[2]]
Out[6]:
        A         B
2 -0.470056  1.192211

#！！！！！！！！！！！！！！！！！！！！！！！！！！！

#定义函数应用训练集计算出标签（价格）
#单变量KNN模型

def predict_price(new_listing_value,feature_column):
    temp_df = train_df
    temp_df['distance'] = np.abs(dc_listings[feature_column] - new_listing_value)
    #得到距离（所选特征与需要测量样本特征之间的）

    temp_df = temp_df.sort_values('distance')
    #按照distance对数据进行排序

    knn_5 = temp_df.price.iloc[:5]
    #取得前5个数据
    predicted_price = knn_5.mean()
    return(predicted_price)

#应用函数得到（test）对应价格（apply对所有样本执行同样的操作，每个样本都执行了predict_price,会产生931个predicted_price）
test_df['predicted_price'] = test_df.accommodates.apply(predict_price,feature_column='accommodates')
#这里每次用到的new_listing_value就是对应行数据的'accommodates'


#计算均方差RMSE
test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)
mse = test_df['squared_error'].mean()
rmse = mse ** (1/2)
rmse

#不同的变量预测得到的RMSE

for feature in ['accommodates','bedrooms','bathrooms','number_of_reviews']:
    #test_df['predicted_price'] = test_df.accommodates.apply(predict_price,feature_column=feature)
    test_df['predicted_price'] = test_df[feature].apply(predict_price,feature_column=feature)
    test_df['squared_error'] = (test_df['predicted_price'] - test_df['price'])**(2)
    mse = test_df['squared_error'].mean()
    rmse = mse ** (1/2)
    print("RMSE for the {} column: {}".format(feature,rmse))


#应用sklearn库将数据进行处理

import pandas as pd
from sklearn.preprocessing import StandardScaler
features = ['accommodates','bedrooms','bathrooms','beds','price','minimum_nights','maximum_nights','number_of_reviews']

dc_listings = pd.read_csv('listings.csv')

dc_listings = dc_listings[features]

dc_listings['price'] = dc_listings.price.str.replace("\$|,",'').astype(float)

dc_listings = dc_listings.dropna()

dc_listings[features] = StandardScaler().fit_transform(dc_listings[features])

normalized_listings = dc_listings

print(dc_listings.shape)

normalized_listings.head()


norm_train_df = normalized_listings.copy().iloc[0:2792]
norm_test_df = normalized_listings.copy().iloc[2792:]

#利用scipy计算便变量距离

from scipy.spatial import distance

first_listing = normalized_listings.iloc[0][['accommodates', 'bathrooms']]
fifth_listing = normalized_listings.iloc[20][['accommodates', 'bathrooms']]
first_fifth_distance = distance.euclidean(first_listing, fifth_listing)
first_fifth_distance

#多变量KNN模型

def predict_price_multivariate(new_listing_value,feature_columns):
    temp_df = norm_train_df
    temp_df['distance'] = distance.cdist(temp_df[feature_columns],[new_listing_value[feature_columns]])
    temp_df = temp_df.sort_values('distance')
    knn_5 = temp_df.price.iloc[:5]
    predicted_price = knn_5.mean()
    return(predicted_price)

cols = ['accommodates', 'bathrooms']

norm_test_df['predicted_price'] = norm_test_df[cols].apply(predict_price_multivariate,feature_columns=cols,axis=1)
norm_test_df['squared_error'] = (norm_test_df['predicted_price'] - norm_test_df['price'])**(2)
mse = norm_test_df['squared_error'].mean()
rmse = mse ** (1/2)
print(rmse)

#用Sklearn来完成KNN

from sklearn.neighbors import KNeighborsRegressor
cols = ['accommodates','bedrooms']
knn = KNeighborsRegressor()
knn.fit(norm_train_df[cols], norm_train_df['price'])
two_features_predictions = knn.predict(norm_test_df[cols])


#计算单变量的误差
from sklearn.metrics import mean_squared_error

two_features_mse = mean_squared_error(norm_test_df['price'], two_features_predictions)
two_features_rmse = two_features_mse ** (1/2)
print(two_features_rmse)

#多变量的误差

knn = KNeighborsRegressor()
#对象实例化

cols = ['accommodates','bedrooms','bathrooms','beds','minimum_nights','maximum_nights','number_of_reviews']
#特征

knn.fit(norm_train_df[cols], norm_train_df['price'])
#拟合

four_features_predictions = knn.predict(norm_test_df[cols])
#得到用test数据计算得到的预测值

four_features_mse = mean_squared_error(norm_test_df['price'], four_features_predictions)
four_features_rmse = four_features_mse ** (1/2)
#计算误差

four_features_rmse
